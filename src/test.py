import sys,os
sys.path.append(os.getcwd())
from dotenv import load_dotenv
load_dotenv()

import gradio as gr
from src.analyzer import AnalyzerContainer
# åˆå§‹åŒ– AnalyzerContainer

import openai
from openai import OpenAI
openai.api_key = os.environ.get("OPENAI_API_KEY","")
openai.base_url = os.environ.get("OPENAI_BASE_URL","")
client = OpenAI(
    api_key=openai.api_key,
    base_url=openai.base_url
)
from src.utils import (
    SUPPORTED_FORMATS,
    MAX_FILE_NUM,
    SUPPORTED_MODELS_DICT,
    get_all_supported_models,
    generate_html_for_file,
    convert_message_dict_to_user_input
)
conversation_history =[]

analyzer_container = AnalyzerContainer()

STAR_URL = os.environ.get("SHEILDS_START_URL","https://img.shields.io/github/stars/HuiyuanYan/gradio_ai_helper?style=plastic")


def predict(message, history,max_history_rounds,temperature,modality,model):
    print(f'Message:{message}\nHistory:{history}')
    assert model in SUPPORTED_MODELS_DICT[modality], f"model {model} not supported for modality {modality}"

    global conversation_history, client
    # æ£€æŸ¥å†å²å¯¹è¯è®°å½•çš„é•¿åº¦æ˜¯å¦è¶…è¿‡æœ€å¤§å…è®¸çš„è½®æ¬¡
    if len(history) > max_history_rounds:
        # å¦‚æœè¶…è¿‡ï¼Œåˆ é™¤æœ€æ—©çš„å¯¹è¯è®°å½•ï¼Œä»¥ä¿æŒå¯¹è¯è®°å½•çš„é•¿åº¦åœ¨æœ€å¤§è½®æ¬¡å†…
        conversation_history = conversation_history[len(history) - max_history_rounds:]
    
    if history:
        # å°†å†å²å¯¹è¯è®°å½•æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
        conversation_history.append(history[-1])

    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œå°†å†å²å¯¹è¯è®°å½•è½¬æ¢ä¸ºopenaiæ ¼å¼
    user_content = convert_message_dict_to_user_input(message,model)
    
    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨ä¸­
    conversation_history.append({"role": "user", "content": user_content})

    # è°ƒç”¨openaiçš„ChatCompletionæ¥å£ï¼Œå‘é€æ¶ˆæ¯åˆ—è¡¨å’Œå…¶ä»–å‚æ•°ï¼Œè·å–å›å¤
    response = client.chat.completions.create(
        model=model,
        messages=conversation_history,
        temperature=temperature,
    )
    
    # ä»å›å¤ä¸­æå–æ–‡æœ¬å†…å®¹
    reply = response.choices[0].message.content
    return reply

def analyze(files):
    ret = []
    file_num = len(files) if files else 0
    for i in range(MAX_FILE_NUM):
        if i < file_num:
            ret.append(analyzer_container.analyze(files[i]))
        else:
            ret.append({})
    return ret


js = """
function createGradioAnimation() {
    var container = document.createElement('div');
    container.id = 'gradio-animation';
    container.style.fontSize = '2em';
    container.style.fontWeight = 'bold';
    container.style.textAlign = 'center';
    container.style.marginBottom = '20px';

    var text = 'ğŸ¤– AIæ™ºèƒ½ä½“åŠ©æ‰‹';
    for (var i = 0; i < text.length; i++) {
        (function(i){
            setTimeout(function(){
                var letter = document.createElement('span');
                letter.style.opacity = '0';
                letter.style.transition = 'opacity 0.5s';
                letter.innerText = text[i];

                container.appendChild(letter);

                setTimeout(function() {
                    letter.style.opacity = '1';
                }, 50);
            }, i * 250);
        })(i);
    }

    var gradioContainer = document.querySelector('.gradio-container');
    gradioContainer.insertBefore(container, gradioContainer.firstChild);

    return 'Animation created';
}
"""

# ç®€åŒ–ç•Œé¢ï¼Œç§»é™¤æ‰‹åŠ¨é€‰æ‹©æ–‡ä»¶ç±»å‹
with gr.Blocks(js=js) as iface:
    gr.Markdown(f"#     ![GitHub stars]({STAR_URL})")
    gr.Markdown("æ”¯æŒå¤šæ¨¡æ€å¯¹è¯ï¼Œä»¥åŠAIGCä¼ªé€ å†…å®¹è¯†åˆ«")
    with gr.Tab("ğŸ—£ï¸ AIå¯¹è¯ "):
        gr.ChatInterface(
            fn=predict,
            type="messages",
            multimodal=True,
            additional_inputs=[
                gr.Slider(1, 10, value=1, label="æœ€å¤§å†å²äº¤äº’è½®æ¬¡", step=1),
                gr.Slider(0,1,value=0.7,label="æ¸©åº¦ï¼Œè¶Šå¤§è¶Šéšæœº"),
                gr.Dropdown(SUPPORTED_MODELS_DICT.keys(),value='image',label="æ¨¡æ€ï¼Œå¯¹è¯å¼€å§‹åä¸è¦æ”¹å˜è¯¥å‚æ•°ï¼"),
                gr.Dropdown(get_all_supported_models(),value='qwen-vl-max-0809',label="æ¨¡å‹ï¼Œå¯¹è¯å¼€å§‹åä¸è¦æ”¹å˜ï¼Œå› ä¸ºä¸åŒæ¨¡å‹çš„ä¼ å‚æ ¼å¼å¯èƒ½ä¸ä¸€æ ·ï¼"),
            ]
        )
    with gr.Tab("ğŸ” å†…å®¹è¯†åˆ«"):
        with gr.Row():
            with gr.Column(f"ä¸Šä¼ æ–‡ä»¶,æœ€å¤šä¸Šä¼ {MAX_FILE_NUM}ä¸ªæ–‡ä»¶",scale=1):
                file_input = gr.File(label="ä¸Šä¼ æ–‡ä»¶ï¼Œæ”¯æŒæ–‡æœ¬ã€è§†é¢‘ã€éŸ³é¢‘ç­‰å¤šç§æ ¼å¼",file_count="multiple",file_types=list(SUPPORTED_FORMATS.keys()))
                
                html_list = [gr.HTML() for _ in range(MAX_FILE_NUM)]
                def show_files(files):
                    ret = []
                    file_num = len(files) if files else 0
                    for i in range(MAX_FILE_NUM):
                        if i < file_num:
                            ret.append(generate_html_for_file(files[i]))
                        else:
                            ret.append("")
                    
                    return ret
                
                file_input.change(show_files,file_input,html_list)
                

            with gr.Column("è¯†åˆ«ç»“æœ",scale=1):
                label_list = [gr.Label(label = f'æ–‡ä»¶{i+1}è¯†åˆ«ç»“æœï¼š',every=0.01) for i in range(MAX_FILE_NUM)]
                btn = gr.Button("å¼€å§‹è¯†åˆ«")
                btn.click(analyze,file_input,label_list)

iface.launch()
